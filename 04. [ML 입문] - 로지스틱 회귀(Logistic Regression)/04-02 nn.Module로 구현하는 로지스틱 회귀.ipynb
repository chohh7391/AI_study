{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41501c72",
   "metadata": {},
   "source": [
    "잠깐만 복습을 해보면 선형 회귀 모델의 가설식은 $H(x) = Wx + b$이었습니다. 그리고 이 가설식을 구현하기 위해서 파이토치의 nn.Linear()를 사용했습니다. 그리고 로지스틱 회귀의 가설식은 $H(x) = sigmoid(Wx + b)$입니다. 파이토치에서는 nn.Sigmoid()를 통해서 시그모이드 함수를 구현하므로 결과적으로 nn.Linear()의 결과를 nn.Sigmoid()를 거치게하면 로지스틱 회귀의 가설식이 됩니다.\n",
    "\n",
    "파이토치를 통해 이를 구현해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c354b",
   "metadata": {},
   "source": [
    "# 1. 파이토치의 nn.Linear와 nn.Sigmoid로 로지스틱 회귀 구현하기\n",
    "\n",
    "---\n",
    "\n",
    "우선 구현을 위해 필요한 파이토치의 도구들을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af12c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e556f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x172ffcc5950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337b80c",
   "metadata": {},
   "source": [
    "훈련 데이터를 텐서로 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c56d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064275a6",
   "metadata": {},
   "source": [
    "nn.Sequential()은 nn.Module 층을 차례로 쌓을 수 있도록 합니다. 뒤에서 이를 이용해서 인공 신경망을 구현하게 되므로 기억하고 있으면 좋습니다. 조금 쉽게 말해서 nn.Sequential()은 $Wx + b$와 같은 수식과 시그모이드 함수 등과 같은 여러 함수들을 연결해주는 역할을 합니다. 이를 이용해서 로지스틱 회귀를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796454c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
    "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e77829",
   "metadata": {},
   "source": [
    "현재 W와 b는 랜덤 초기화가 된 상태입니다. 훈련 데이터를 넣어 예측값을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfaf1044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4020],\n",
       "        [0.4147],\n",
       "        [0.6556],\n",
       "        [0.5948],\n",
       "        [0.6788],\n",
       "        [0.8061]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fcc6db",
   "metadata": {},
   "source": [
    "6 × 1 크기의 예측값 텐서가 출력됩니다. 그러나 현재 W와 b는 임의의 값을 가지므로 현재의 예측은 의미가 없습니다.\n",
    "이제 경사 하강법을 사용하여 훈련해보겠습니다. 총 100번의 에포크를 수행합니다.\n",
    "\n",
    "각 에포크마다 정확도를 계산하여 정확도도 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c246cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
      "Epoch   10/1000 Cost: 0.614852 Accuracy 66.67%\n",
      "Epoch   20/1000 Cost: 0.441875 Accuracy 66.67%\n",
      "Epoch   30/1000 Cost: 0.373145 Accuracy 83.33%\n",
      "Epoch   40/1000 Cost: 0.316358 Accuracy 83.33%\n",
      "Epoch   50/1000 Cost: 0.266094 Accuracy 83.33%\n",
      "Epoch   60/1000 Cost: 0.220498 Accuracy 100.00%\n",
      "Epoch   70/1000 Cost: 0.182095 Accuracy 100.00%\n",
      "Epoch   80/1000 Cost: 0.157299 Accuracy 100.00%\n",
      "Epoch   90/1000 Cost: 0.144091 Accuracy 100.00%\n",
      "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
      "Epoch  110/1000 Cost: 0.125769 Accuracy 100.00%\n",
      "Epoch  120/1000 Cost: 0.118297 Accuracy 100.00%\n",
      "Epoch  130/1000 Cost: 0.111680 Accuracy 100.00%\n",
      "Epoch  140/1000 Cost: 0.105779 Accuracy 100.00%\n",
      "Epoch  150/1000 Cost: 0.100483 Accuracy 100.00%\n",
      "Epoch  160/1000 Cost: 0.095704 Accuracy 100.00%\n",
      "Epoch  170/1000 Cost: 0.091369 Accuracy 100.00%\n",
      "Epoch  180/1000 Cost: 0.087420 Accuracy 100.00%\n",
      "Epoch  190/1000 Cost: 0.083806 Accuracy 100.00%\n",
      "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
      "Epoch  210/1000 Cost: 0.077425 Accuracy 100.00%\n",
      "Epoch  220/1000 Cost: 0.074595 Accuracy 100.00%\n",
      "Epoch  230/1000 Cost: 0.071969 Accuracy 100.00%\n",
      "Epoch  240/1000 Cost: 0.069526 Accuracy 100.00%\n",
      "Epoch  250/1000 Cost: 0.067248 Accuracy 100.00%\n",
      "Epoch  260/1000 Cost: 0.065118 Accuracy 100.00%\n",
      "Epoch  270/1000 Cost: 0.063122 Accuracy 100.00%\n",
      "Epoch  280/1000 Cost: 0.061247 Accuracy 100.00%\n",
      "Epoch  290/1000 Cost: 0.059483 Accuracy 100.00%\n",
      "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
      "Epoch  310/1000 Cost: 0.056250 Accuracy 100.00%\n",
      "Epoch  320/1000 Cost: 0.054764 Accuracy 100.00%\n",
      "Epoch  330/1000 Cost: 0.053357 Accuracy 100.00%\n",
      "Epoch  340/1000 Cost: 0.052022 Accuracy 100.00%\n",
      "Epoch  350/1000 Cost: 0.050753 Accuracy 100.00%\n",
      "Epoch  360/1000 Cost: 0.049546 Accuracy 100.00%\n",
      "Epoch  370/1000 Cost: 0.048396 Accuracy 100.00%\n",
      "Epoch  380/1000 Cost: 0.047299 Accuracy 100.00%\n",
      "Epoch  390/1000 Cost: 0.046252 Accuracy 100.00%\n",
      "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
      "Epoch  410/1000 Cost: 0.044294 Accuracy 100.00%\n",
      "Epoch  420/1000 Cost: 0.043376 Accuracy 100.00%\n",
      "Epoch  430/1000 Cost: 0.042497 Accuracy 100.00%\n",
      "Epoch  440/1000 Cost: 0.041653 Accuracy 100.00%\n",
      "Epoch  450/1000 Cost: 0.040843 Accuracy 100.00%\n",
      "Epoch  460/1000 Cost: 0.040064 Accuracy 100.00%\n",
      "Epoch  470/1000 Cost: 0.039315 Accuracy 100.00%\n",
      "Epoch  480/1000 Cost: 0.038593 Accuracy 100.00%\n",
      "Epoch  490/1000 Cost: 0.037898 Accuracy 100.00%\n",
      "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
      "Epoch  510/1000 Cost: 0.036582 Accuracy 100.00%\n",
      "Epoch  520/1000 Cost: 0.035958 Accuracy 100.00%\n",
      "Epoch  530/1000 Cost: 0.035356 Accuracy 100.00%\n",
      "Epoch  540/1000 Cost: 0.034773 Accuracy 100.00%\n",
      "Epoch  550/1000 Cost: 0.034210 Accuracy 100.00%\n",
      "Epoch  560/1000 Cost: 0.033664 Accuracy 100.00%\n",
      "Epoch  570/1000 Cost: 0.033137 Accuracy 100.00%\n",
      "Epoch  580/1000 Cost: 0.032625 Accuracy 100.00%\n",
      "Epoch  590/1000 Cost: 0.032130 Accuracy 100.00%\n",
      "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
      "Epoch  610/1000 Cost: 0.031183 Accuracy 100.00%\n",
      "Epoch  620/1000 Cost: 0.030730 Accuracy 100.00%\n",
      "Epoch  630/1000 Cost: 0.030291 Accuracy 100.00%\n",
      "Epoch  640/1000 Cost: 0.029864 Accuracy 100.00%\n",
      "Epoch  650/1000 Cost: 0.029449 Accuracy 100.00%\n",
      "Epoch  660/1000 Cost: 0.029046 Accuracy 100.00%\n",
      "Epoch  670/1000 Cost: 0.028654 Accuracy 100.00%\n",
      "Epoch  680/1000 Cost: 0.028272 Accuracy 100.00%\n",
      "Epoch  690/1000 Cost: 0.027900 Accuracy 100.00%\n",
      "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
      "Epoch  710/1000 Cost: 0.027186 Accuracy 100.00%\n",
      "Epoch  720/1000 Cost: 0.026842 Accuracy 100.00%\n",
      "Epoch  730/1000 Cost: 0.026507 Accuracy 100.00%\n",
      "Epoch  740/1000 Cost: 0.026181 Accuracy 100.00%\n",
      "Epoch  750/1000 Cost: 0.025862 Accuracy 100.00%\n",
      "Epoch  760/1000 Cost: 0.025552 Accuracy 100.00%\n",
      "Epoch  770/1000 Cost: 0.025248 Accuracy 100.00%\n",
      "Epoch  780/1000 Cost: 0.024952 Accuracy 100.00%\n",
      "Epoch  790/1000 Cost: 0.024663 Accuracy 100.00%\n",
      "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
      "Epoch  810/1000 Cost: 0.024104 Accuracy 100.00%\n",
      "Epoch  820/1000 Cost: 0.023835 Accuracy 100.00%\n",
      "Epoch  830/1000 Cost: 0.023571 Accuracy 100.00%\n",
      "Epoch  840/1000 Cost: 0.023313 Accuracy 100.00%\n",
      "Epoch  850/1000 Cost: 0.023061 Accuracy 100.00%\n",
      "Epoch  860/1000 Cost: 0.022814 Accuracy 100.00%\n",
      "Epoch  870/1000 Cost: 0.022572 Accuracy 100.00%\n",
      "Epoch  880/1000 Cost: 0.022336 Accuracy 100.00%\n",
      "Epoch  890/1000 Cost: 0.022104 Accuracy 100.00%\n",
      "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
      "Epoch  910/1000 Cost: 0.021655 Accuracy 100.00%\n",
      "Epoch  920/1000 Cost: 0.021437 Accuracy 100.00%\n",
      "Epoch  930/1000 Cost: 0.021224 Accuracy 100.00%\n",
      "Epoch  940/1000 Cost: 0.021015 Accuracy 100.00%\n",
      "Epoch  950/1000 Cost: 0.020810 Accuracy 100.00%\n",
      "Epoch  960/1000 Cost: 0.020609 Accuracy 100.00%\n",
      "Epoch  970/1000 Cost: 0.020412 Accuracy 100.00%\n",
      "Epoch  980/1000 Cost: 0.020219 Accuracy 100.00%\n",
      "Epoch  990/1000 Cost: 0.020029 Accuracy 100.00%\n",
      "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f08557",
   "metadata": {},
   "source": [
    "중간부터 정확도는 100%가 나오기 시작합니다. 기존의 훈련 데이터를 입력하여 예측값을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a133e611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7616e-04],\n",
       "        [3.1595e-02],\n",
       "        [3.8959e-02],\n",
       "        [9.5624e-01],\n",
       "        [9.9823e-01],\n",
       "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9244e57",
   "metadata": {},
   "source": [
    "0.5를 넘으면 True, 그보다 낮으면 False로 간주합니다. 실제값은 [[0], [0], [0], [1], [1], [1]]입니다. 이는 False, False, False, True, True, True에 해당되므로 전부 실제값과 일치하도록 예측한 것을 확인할 수 있습니다.\n",
    "\n",
    "훈련 후의 W와 b의 값을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a50e5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[3.2534, 1.5181]], requires_grad=True), Parameter containing:\n",
      "tensor([-14.4839], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd51ab",
   "metadata": {},
   "source": [
    "출력값이 앞 챕터에서 nn.Module을 사용하지 않고 로지스틱 회귀를 구현한 실습에서 얻었던 W와 b와 거의 일치합니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2a6b196a",
   "metadata": {},
   "source": [
    "# 2. 인공 신경망으로 표현되는 로지스틱 회귀.\n",
    "\n",
    "---\n",
    "\n",
    "사실 로지스틱 회귀는 인공 신경망으로 간주할 수 있습니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "위의 인공 신경망 그림에서 각 화살표는 입력과 곱해지는 가중치 또는 편향입니다. 각 입력에 대해서 검은색 화살표는 가중치, 회색 화살표는 편향이 곱해집니다. 각 입력 $x$\n",
    "는 각 입력의 가중치 $w$와 곱해지고, 편향 $b$는 상수 1과 곱해지는 것으로 표현되었습니다. 그리고 출력하기 전에 시그모이드 함수를 지나게 됩니다.\n",
    "\n",
    "결과적으로 위의 인공 신경망은 다음과 같은 다중 로지스틱 회귀를 표현하고 있습니다.\n",
    "\n",
    "$$\n",
    "H(x)=sigmoid(x_{1}w_{1} + x_{2}w_{2} + b)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "+ **뒤에서 인공 신경망을 배우면서 언급하겠지만, 시그모이드 함수는 인공 신경망의 은닉층에서는 거의 사용되지 않습니다.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
